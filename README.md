# LLM-From-Scratch

This repository contains my personal journey of building a Large Language Model (LLM) from scratch using Python and PyTorch.


## What this project includes : 

Custom tokenizer and data preparation

Implementation of self-attention, multi-head attention, and feed-forward networks

A full Transformer architecture built from the ground up

Experiments, notes, and progressive improvements as I learn each concept

## Goal

To deeply understand how modern LLMs work internally by rebuilding each component manually, improving with each iteration, and documenting the entire learning process.
